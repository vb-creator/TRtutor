{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a11aaa29",
   "metadata": {},
   "source": [
    "dummy implementation of talker-reasoner with openai API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285dda7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasoner_output='```json\\n{\\n  \"confusion_inference\": \"Steven seems to understand the concept of tripling a number, as he correctly calculated 4 times 3 to get 12. However, the teacher noted that he might have added an extra step, which suggests he may be overthinking or misinterpreting the problem\\'s requirements.\",\\n  \"proficiency_update\": {\\n    \"multiplication\": 0.7,\\n    \"fractions\": 0.4\\n  },\\n  \"solution\": {\\n    \"step_by_step\": [\\n      \"Start with the number 4.\",\\n      \"To triple a number, multiply it by 3.\",\\n      \"Calculate 4 * 3 = 12.\",\\n      \"The result is 12.\"\\n    ],\\n    \"final_answer\": 12\\n  },\\n  \"clarifying_questions\": []\\n}\\n```'\n",
      "talker_output='```json\\n{\\n  \"next_message\": \"Great job, Steven! You got the right answer by tripling 4 to get 12. Just to make sure we\\'re on the same page, when you hear \\'triple,\\' what steps do you think of? It seems like you nailed it, but sometimes it\\'s helpful to check our thought process!\"\\n}\\n```'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import Dict, Any, List\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=keys[\"OPENAI_API_KEY\"])\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    keys = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT_REASONER = \"\"\"\n",
    "You are a multi-step math reasoner.\n",
    "Given the conversation, student profile, and question metadata:\n",
    "1. Infer the student’s confusion.\n",
    "2. Update their proficiency levels.\n",
    "3. Solve the math problem step by step (chain of thought).\n",
    "4. If details are missing to correctly solve a question, generate clarifying questions.\n",
    "These clarifying questions should be simple and easy to answer, and ensure you don't make any assumption when you solve the problem.\n",
    "Output exactly a JSON matching the ReasonerOutput schema.\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT_TALKER = \"\"\"\n",
    "You are a conversational tutor.\n",
    "Given the shared context (conversation + reasoner output):\n",
    "- Use the reasoner's chain_of_thought and belief state\n",
    "- Produce a friendly Socratic prompt to guide the student\n",
    "Output exactly a JSON with fields: { \"next_message\": <string> }.\n",
    "\"\"\"\n",
    "\n",
    "# {\n",
    "#   \"belief_state\": {...},\n",
    "#   \"chain_of_thought\": [...],\n",
    "#   \"final_answer\": \"...\",\n",
    "#   \"clarification_questions\": [...]\n",
    "# }\n",
    "\n",
    "\n",
    "class TalkerReasonerPipeline:\n",
    "    def __init__(self, model: str = \"gpt-4o\"):\n",
    "        self.model = model\n",
    "\n",
    "    def build_shared_context(self,\n",
    "                             conversation: List[Dict[str, str]],\n",
    "                             student_profile: Dict[str, Any],\n",
    "                             question_metadata: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"conversation\": conversation,\n",
    "            \"student_profile\": student_profile,\n",
    "            \"question_metadata\": question_metadata\n",
    "        }\n",
    "\n",
    "    def call_reasoner(self, context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT_REASONER},\n",
    "            {\"role\": \"user\", \"content\": json.dumps(context)}\n",
    "        ]\n",
    "        response = client.chat.completions.create(model=self.model,\n",
    "        # reasoning={\"effort\": \"medium\", \"summary\": \"auto\"},\n",
    "        messages=messages,\n",
    "        temperature=0.2)\n",
    "        text = response.choices[0].message.content\n",
    "        # return json.loads(text)\n",
    "        return text\n",
    "\n",
    "    def call_talker(self, context: Dict[str, Any], reasoner_out: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        # merge reasoner output into shared context\n",
    "        shared = {**context, **{\"reasoner_output\": reasoner_out}}\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT_TALKER},\n",
    "            {\"role\": \"user\", \"content\": json.dumps(shared)}\n",
    "        ]\n",
    "        response = client.chat.completions.create(model=self.model,\n",
    "        messages=messages,\n",
    "        temperature=0.7)\n",
    "        text = response.choices[0].message.content\n",
    "        # return json.loads(text)\n",
    "        return text\n",
    "\n",
    "    def update_context(self,\n",
    "                       context: Dict[str, Any],\n",
    "                       reasoner_out: Dict[str, Any],\n",
    "                       talker_out: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        # context[\"conversation\"].append(\n",
    "        #     {\"role\": \"reasoner\", \"text\": reasoner_out.get(\"chain_of_thought\", [])}\n",
    "        # )\n",
    "        # context[\"conversation\"].append(\n",
    "        #     {\"role\": \"talker\", \"text\": talker_out.get(\"next_message\", \"\")}    )\n",
    "\n",
    "        # bs = reasoner_out.get(\"belief_state\", {})\n",
    "        # prof = context[\"student_profile\"].get(\"proficiency\", {})\n",
    "        # prof.update(bs.get(\"proficiency_update\", {}))\n",
    "        # context[\"student_profile\"][\"proficiency\"] = prof\n",
    "\n",
    "        return context\n",
    "\n",
    "\n",
    "TALKER_MODEL   = \"gpt-4o\" \n",
    "REASON_MODEL     = \"o3-mini\"\n",
    "\n",
    "pipeline = TalkerReasonerPipeline(model=TALKER_MODEL)\n",
    "\n",
    "# Initial context provided\n",
    "context = pipeline.build_shared_context(\n",
    "    conversation=[\n",
    "        {\"role\":\"teacher\",\"text\":\"Steven, If you had 4 of something and tripled that amount, how much would you have?\"},\n",
    "        {\"role\":\"student\",\"text\":\"I would have 12 of something.\"}\n",
    "    ],\n",
    "    student_profile={\n",
    "        \"name\":\"Steven\",\"grade\":7,\n",
    "        \"proficiency\":{\"multiplication\":0.6,\"fractions\":0.4}\n",
    "    },\n",
    "    question_metadata={\n",
    "        \"original_question\":\"If you had 4…tripled…\",\n",
    "        \"teacher_described_confusion\":\"He added an extra step after solving.\"\n",
    "    }\n",
    ")\n",
    "\n",
    "reasoner_output = pipeline.call_reasoner(context)\n",
    "# print(\"Reasoner output:\", json.dumps(reasoner_output, indent=2))\n",
    "print(f\"{reasoner_output=}\")\n",
    "\n",
    "talker_output = pipeline.call_talker(context, reasoner_output)\n",
    "# print(\"Talker output:\", json.dumps(talker_output, indent=2))\n",
    "print(f\"{talker_output=}\")\n",
    "\n",
    "# updated_context = pipeline.update_context(context, reasoner_output, talker_output)\n",
    "# # print(\"Updated shared context:\", json.dumps(updated_context, indent=2))\n",
    "# print(f\"{updated_context=}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc197d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trtutor-TaY_8dL0-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
